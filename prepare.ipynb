{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load `vertices/edges` \"\"\"\n",
    "\n",
    "from polars import DataFrame\n",
    "\n",
    "vertices = dict[str, DataFrame]()\n",
    "raw_edges = dict[tuple[str, str, str], DataFrame]()\n",
    "switch_namespace = dict[str, dict[int, int]]()\n",
    "\n",
    "for file in glob.glob(f\"{RAW_DATA_PREFIX}/*.csv\"):\n",
    "    df_name = os.path.basename(file).split(\".\")[0]\n",
    "    if \"_\" in df_name:\n",
    "        src, relationship, dst = df_name.split(\"_\")\n",
    "        raw_edges[(src, relationship, dst)] = pl.read_csv(file)\n",
    "    else:\n",
    "        vertices[df_name] = pl.read_csv(file)\n",
    "\n",
    "\n",
    "vertex_num = sum(len(df) for df in vertices.values())\n",
    "edge_num = sum(len(df) for df in raw_edges.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Commentid': {},\n",
       " 'Forumid': {},\n",
       " 'Organisationid': {},\n",
       " 'Personid': {},\n",
       " 'Placeid': {},\n",
       " 'Postid': {},\n",
       " 'Tagid': {},\n",
       " 'TagClassid': {}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Initialize `switch_namespace` \"\"\"\n",
    "\n",
    "for df in vertices.values():\n",
    "    base_label = get_namespace(df.columns[0])\n",
    "    switch_namespace[base_label] = dict()\n",
    "\n",
    "switch_namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping `origin_id` to `uni_id`:   0%|          | 0/3181724 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping `origin_id` to `uni_id`: 100%|██████████| 3181724/3181724 [00:03<00:00, 920189.47it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Commentid',\n",
       " 'Forumid',\n",
       " 'Organisationid',\n",
       " 'Personid',\n",
       " 'Placeid',\n",
       " 'Postid',\n",
       " 'TagClassid',\n",
       " 'Tagid'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Re-arrange all `:ID($AnyNamespace)` \"\"\"\n",
    "\n",
    "curr_global_id = 0\n",
    "\n",
    "with tqdm(desc=\"Mapping `origin_id` to `uni_id`\", total=vertex_num) as bar:\n",
    "    for df in vertices.values():\n",
    "        base_label = get_namespace(df.columns[0])\n",
    "        map = switch_namespace[base_label]\n",
    "        for row in df.rows():\n",
    "            map[int(row[0])] = curr_global_id\n",
    "            curr_global_id += 1\n",
    "            bar.update(1)\n",
    "\n",
    "assert curr_global_id == vertex_num\n",
    "set(switch_namespace.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build `original` dg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldbc_tools.data_graph import *\n",
    "\n",
    "labels = dict[int, str]()\n",
    "label_set = set[str]()\n",
    "\n",
    "\n",
    "def place_op(df: DataFrame):\n",
    "    namespace = get_namespace(df.columns[0])\n",
    "    map = switch_namespace[namespace]\n",
    "    slice = df.select(\n",
    "        [\n",
    "            pl.col(df.columns[0]),\n",
    "            pl.col(\"name\"),\n",
    "            pl.col(\":TYPE\"),\n",
    "        ]\n",
    "    )\n",
    "    for oid, name, ty in slice.rows():\n",
    "        oid, name, label = int(oid), str(name), str(ty)\n",
    "        uid = map[oid]\n",
    "        if name in explicit_place_labels:\n",
    "            label = BaseLabel.Country + name\n",
    "        labels[uid] = label\n",
    "        label_set.add(label)\n",
    "        bar.update(1)\n",
    "\n",
    "\n",
    "def person_op(df: DataFrame):\n",
    "    namespace = get_namespace(df.columns[0])\n",
    "    map = switch_namespace[namespace]\n",
    "    slice = df.select(\n",
    "        [\n",
    "            pl.col(df.columns[0]),\n",
    "            pl.col(\":LABEL\"),\n",
    "        ]\n",
    "    )\n",
    "    for x, y in slice.rows():\n",
    "        personId = int(x)\n",
    "        generalLabel = str(y)\n",
    "        uid = map[personId]\n",
    "        label = (\n",
    "            generalLabel\n",
    "            if not personId in explicit_personId_labels\n",
    "            else BaseLabel.PersonId + str(personId)\n",
    "        )\n",
    "        labels[uid] = label\n",
    "        label_set.add(label)\n",
    "        bar.update(1)\n",
    "\n",
    "\n",
    "def tagclass_op(df: DataFrame):\n",
    "    namespace = get_namespace(df.columns[0])\n",
    "    map = switch_namespace[namespace]\n",
    "    slice = df.select(\n",
    "        [\n",
    "            pl.col(df.columns[0]),\n",
    "            pl.col(df.columns[1]),\n",
    "            pl.col(\":LABEL\"),\n",
    "        ]\n",
    "    )\n",
    "    for oid, tagclass_name, label in slice.rows():\n",
    "        uid = map[int(oid)]\n",
    "        label = (\n",
    "            str(label)\n",
    "            if not str(tagclass_name) in explicit_tagclass_labels\n",
    "            else BaseLabel.TagClass + str(tagclass_name)\n",
    "        )\n",
    "        labels[uid] = label\n",
    "        label_set.add(label)\n",
    "        bar.update(1)\n",
    "\n",
    "\n",
    "def forum_op(df: DataFrame):\n",
    "    namespace = get_namespace(df.columns[0])\n",
    "    map = switch_namespace[namespace]\n",
    "    slice = df.select(\n",
    "        [\n",
    "            pl.col(df.columns[0]),\n",
    "            pl.col(df.columns[2]),\n",
    "            pl.col(\":LABEL\"),\n",
    "        ]\n",
    "    )\n",
    "    for oid, creationDate, label in slice.rows():\n",
    "        uid = map[int(oid)]\n",
    "        labels[uid] = (\n",
    "            str(label)\n",
    "            if not int(creationDate) in explicit_date_labels\n",
    "            else BaseLabel.Date + str(creationDate)\n",
    "        )\n",
    "        label_set.add(str(label))\n",
    "        bar.update(1)\n",
    "\n",
    "\n",
    "def normal_op(df: DataFrame):\n",
    "    namespace = get_namespace(df.columns[0])\n",
    "    map = switch_namespace[namespace]\n",
    "    slice = df.select(\n",
    "        [\n",
    "            pl.col(df.columns[0]),\n",
    "            pl.col(\":TYPE\" if \":TYPE\" in df.columns else \":LABEL\"),\n",
    "        ]\n",
    "    )\n",
    "    for oid, label in slice.rows():\n",
    "        uid = map[int(oid)]\n",
    "        labels[uid] = str(label)\n",
    "        label_set.add(str(label))\n",
    "        bar.update(1)\n",
    "\n",
    "\n",
    "def vertex_op(df_name: str, df: DataFrame):\n",
    "    match df_name:\n",
    "        case \"place\":\n",
    "            place_op(df)\n",
    "        case \"person\":\n",
    "            person_op(df)\n",
    "        case \"tagclass\":\n",
    "            tagclass_op(df)\n",
    "        case \"forum\":\n",
    "            forum_op(df)\n",
    "        case _:\n",
    "            normal_op(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build map of `vertex.uni_id -> label`: 100%|██████████| 3181724/3181724 [00:02<00:00, 1576756.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'city',\n",
       " 'comment',\n",
       " 'company',\n",
       " 'continent',\n",
       " 'country',\n",
       " 'country(Belgium)',\n",
       " 'country(Chile)',\n",
       " 'country(China)',\n",
       " 'country(Cuba)',\n",
       " 'country(France)',\n",
       " 'country(Greece)',\n",
       " 'country(India)',\n",
       " 'country(Tunisia)',\n",
       " 'forum',\n",
       " 'person',\n",
       " 'post',\n",
       " 'tag',\n",
       " 'tagClass(NascarDriver)',\n",
       " 'tagClass(Politician)',\n",
       " 'tagClass(President)',\n",
       " 'tagClass(Saint)',\n",
       " 'tagClass(Song)',\n",
       " 'tagClass(Thing)',\n",
       " 'tagclass',\n",
       " 'university'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Build map of `vertex.uid -> label` \"\"\"\n",
    "\n",
    "with tqdm(desc=\"Build map of `vertex.uni_id -> label`\", total=vertex_num) as bar:\n",
    "    for df_name, df in vertices.items():\n",
    "        vertex_op(df_name, df)\n",
    "\n",
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build edges in format: `(src_id, dst_id)`: 100%|██████████| 17256038/17256038 [00:17<00:00, 962410.00it/s] \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Build edges in format: `(src_id, dst_id)` \"\"\"\n",
    "\n",
    "edges = set[tuple[int, int]]()\n",
    "\n",
    "with tqdm(desc=\"Build edges in format: `(src_id, dst_id)`\", total=edge_num) as bar:\n",
    "    for df_name, df in raw_edges.items():\n",
    "        src_namespace = get_namespace(df.columns[0])\n",
    "        dst_namespace = get_namespace(df.columns[1])\n",
    "        src_map = switch_namespace[src_namespace]\n",
    "        dst_map = switch_namespace[dst_namespace]\n",
    "        slice = df.select(\n",
    "            [\n",
    "                pl.col(df.columns[0]),\n",
    "                pl.col(df.columns[1]),\n",
    "            ]\n",
    "        )\n",
    "        for src_id, dst_id in slice.rows():\n",
    "            src_uni_id = src_map[int(src_id)]\n",
    "            dst_uni_id = dst_map[int(dst_id)]\n",
    "            edges.add((src_uni_id, dst_uni_id))\n",
    "            bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing `labels` into `./out/original/data_graph.txt`: 100%|██████████| 3181724/3181724 [00:02<00:00, 1584289.41it/s]\n",
      "Writing `edges` into `./out/original/data_graph.txt`: 100%|██████████| 17256033/17256033 [00:19<00:00, 887977.23it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Write into `data_graph.txt` \"\"\"\n",
    "\n",
    "if not os.path.exists(COMMON_DG):\n",
    "    with open(COMMON_DG, \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(labels)}\\n\")\n",
    "        with tqdm(\n",
    "            desc=f\"Writing `labels` into `{COMMON_DG}`\", total=len(labels)\n",
    "        ) as bar:\n",
    "            for i in range(len(labels)):\n",
    "                f.write(f\"{labels[i]}\\n\")\n",
    "                bar.update(1)\n",
    "        f.write(f\"{len(edges)}\\n\")\n",
    "        with tqdm(desc=f\"Writing `edges` into `{COMMON_DG}`\", total=len(edges)) as bar:\n",
    "            for src, dst in edges:\n",
    "                f.write(f\"{src} {dst}\\n\")\n",
    "                bar.update(1)\n",
    "else:\n",
    "    print(f\"File `{COMMON_DG}` already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build `optimized` dg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load all `index edge` \"\"\"\n",
    "\n",
    "index_edges = dict[str, DataFrame]()\n",
    "\n",
    "for file in glob.glob(f\"{INDEX_EDGES_PREFIX}/*.csv\"):\n",
    "    df_name = os.path.basename(file).split(\".\")[0]\n",
    "    index_edges[df_name] = pl.read_csv(file)\n",
    "\n",
    "index_edge_num = sum(len(df) for df in index_edges.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding `index edge` into `edges`: 100%|██████████| 20605002/20605002 [00:32<00:00, 639311.85it/s] \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Add `index edge` into `edges` \"\"\"\n",
    "\n",
    "with tqdm(desc=\"Adding `index edge` into `edges`\", total=index_edge_num) as bar:\n",
    "    for df in index_edges.values():\n",
    "        # need to unique!\n",
    "        # see `./data/index/forum_country.csv` for example\n",
    "        unique_current_edges = set[tuple[int, int]]()\n",
    "\n",
    "        src_namespace = get_namespace(df.columns[0])\n",
    "        dst_namespace = get_namespace(df.columns[1])\n",
    "        src_map = switch_namespace[src_namespace]\n",
    "        dst_map = switch_namespace[dst_namespace]\n",
    "        slice = df.select(\n",
    "            [\n",
    "                pl.col(df.columns[0]),\n",
    "                pl.col(df.columns[1]),\n",
    "            ]\n",
    "        )\n",
    "        for src_id, dst_id in slice.rows():\n",
    "            src_uni_id = src_map[int(src_id)]\n",
    "            dst_uni_id = dst_map[int(dst_id)]\n",
    "            if not (src_uni_id, dst_uni_id) in unique_current_edges:\n",
    "                edges.add((src_uni_id, dst_uni_id))\n",
    "                unique_current_edges.add((src_uni_id, dst_uni_id))\n",
    "            bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing `labels` into `./out/optimized/data_graph.txt`: 100%|██████████| 3181724/3181724 [00:02<00:00, 1557418.00it/s]\n",
      "Writing `edges` into `./out/optimized/data_graph.txt`: 100%|██████████| 34775921/34775921 [00:38<00:00, 909350.60it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Write into `data_graph.txt` \"\"\"\n",
    "\n",
    "if not os.path.exists(COMMON_DG_OPTIMIZED):\n",
    "    with open(COMMON_DG_OPTIMIZED, \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(labels)}\\n\")\n",
    "        with tqdm(\n",
    "            desc=f\"Writing `labels` into `{COMMON_DG_OPTIMIZED}`\", total=len(labels)\n",
    "        ) as bar:\n",
    "            for i in range(len(labels)):\n",
    "                f.write(f\"{labels[i]}\\n\")\n",
    "                bar.update(1)\n",
    "        f.write(f\"{len(edges)}\\n\")\n",
    "        with tqdm(\n",
    "            desc=f\"Writing `edges` into `{COMMON_DG_OPTIMIZED}`\", total=len(edges)\n",
    "        ) as bar:\n",
    "            for src, dst in edges:\n",
    "                f.write(f\"{src} {dst}\\n\")\n",
    "                bar.update(1)\n",
    "else:\n",
    "    print(f\"File `{COMMON_DG_OPTIMIZED}` already exists\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
