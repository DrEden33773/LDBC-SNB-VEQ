{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import re, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PREFIX = \"./data\"\n",
    "RAW_DATA_PREFIX = f\"{DATA_PREFIX}/raw\"\n",
    "INDEX_EDGES_PREFIX = f\"{DATA_PREFIX}/index\"\n",
    "\n",
    "if not os.path.exists(INDEX_EDGES_PREFIX):\n",
    "    os.makedirs(INDEX_EDGES_PREFIX)\n",
    "if not os.path.exists(RAW_DATA_PREFIX):\n",
    "    os.makedirs(RAW_DATA_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forumid'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Function Tools \"\"\"\n",
    "\n",
    "import subprocess\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def run_veq_m_100k(\n",
    "    result_path: str,\n",
    "    task_name: str,\n",
    "    args: list[str],\n",
    "    time_table: Optional[list[float]] = None,\n",
    "):\n",
    "    if os.path.exists(result_path):\n",
    "        print(f\"File `{result_path}` already exists\")\n",
    "        with open(result_path, \"r\") as f:\n",
    "            non_empty_lines = [line for line in f if line.strip() != \"\"]\n",
    "            last_line = non_empty_lines[-1]\n",
    "            print(f\"    last_line ~> {last_line}\")\n",
    "            time = float(last_line.split(\" \")[-1])\n",
    "            if not time_table is None:\n",
    "                time_table.append(time)\n",
    "        return\n",
    "\n",
    "    content = \"\"\n",
    "    with open(result_path, \"w\") as f:\n",
    "        print(f\">>> Running: {task_name}...\")\n",
    "        with subprocess.Popen(\n",
    "            args,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "        ) as p:\n",
    "            if p.stdout:\n",
    "                for line in iter(p.stdout.readline, b\"\"):\n",
    "                    content = line.decode(\"utf-8\")\n",
    "                    print(\"    \" + content, end=\"\")\n",
    "                    f.write(content)\n",
    "            else:\n",
    "                print(\"    <No output>\")\n",
    "                f.write(\"<No output>\")\n",
    "        print(\"<<< Done!\")\n",
    "    if not time_table is None:\n",
    "        processing_time = float(content.split(\" \")[-1])\n",
    "        time_table.append(processing_time)\n",
    "\n",
    "\n",
    "def get_inner_namespace(col_name: str) -> str:\n",
    "    match = re.search(\"\\((.*?)\\)\", col_name)\n",
    "    return \"\" if match is None else match.group(1)\n",
    "\n",
    "\n",
    "def get_namespace(col_name: str) -> str:\n",
    "    inner_namespace = get_inner_namespace(col_name)\n",
    "    if inner_namespace in [\"Country\", \"Continent\", \"City\"]:\n",
    "        return \"Placeid\"\n",
    "    if inner_namespace in [\"University\", \"Company\"]:\n",
    "        return \"Organisationid\"\n",
    "    return inner_namespace\n",
    "\n",
    "\n",
    "# demo\n",
    "get_namespace(\":ID(Forumid)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>:ID(Placeid)</th><th>name</th><th>:TYPE</th><th>:LABEL</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;India&quot;</td><td>&quot;country&quot;</td><td>&quot;place&quot;</td></tr><tr><td>1</td><td>&quot;China&quot;</td><td>&quot;country&quot;</td><td>&quot;place&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌──────────────┬───────┬─────────┬────────┐\n",
       "│ :ID(Placeid) ┆ name  ┆ :TYPE   ┆ :LABEL │\n",
       "│ ---          ┆ ---   ┆ ---     ┆ ---    │\n",
       "│ i64          ┆ str   ┆ str     ┆ str    │\n",
       "╞══════════════╪═══════╪═════════╪════════╡\n",
       "│ 0            ┆ India ┆ country ┆ place  │\n",
       "│ 1            ┆ China ┆ country ┆ place  │\n",
       "└──────────────┴───────┴─────────┴────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Test \"\"\"\n",
    "\n",
    "PLACE = f\"{RAW_DATA_PREFIX}/place.csv\"\n",
    "\n",
    "df = pl.read_csv(PLACE)\n",
    "test_table = df.lazy().filter(pl.col(\"name\").is_in([\"India\", \"China\"])).collect()\n",
    "out = test_table.select(\n",
    "    [\n",
    "        pl.col(\":ID(Placeid)\"),\n",
    "        pl.col(\"name\"),\n",
    "        pl.col(\":TYPE\"),\n",
    "        pl.col(\":LABEL\"),\n",
    "    ]\n",
    ")\n",
    "out.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load `vertices/edges` \"\"\"\n",
    "\n",
    "import os, glob\n",
    "from polars import DataFrame\n",
    "\n",
    "vertices = dict[str, DataFrame]()\n",
    "raw_edges = dict[tuple[str, str, str], DataFrame]()\n",
    "switch_namespace = dict[str, dict[int, int]]()\n",
    "\n",
    "for file in glob.glob(f\"{RAW_DATA_PREFIX}/*.csv\"):\n",
    "    df_name = os.path.basename(file).split(\".\")[0]\n",
    "    if \"_\" in df_name:\n",
    "        src, relationship, dst = df_name.split(\"_\")\n",
    "        raw_edges[(src, relationship, dst)] = pl.read_csv(file)\n",
    "    else:\n",
    "        vertices[df_name] = pl.read_csv(file)\n",
    "\n",
    "\n",
    "vertex_num = sum(len(df) for df in vertices.values())\n",
    "edge_num = sum(len(df) for df in raw_edges.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Commentid': {},\n",
       " 'Forumid': {},\n",
       " 'Organisationid': {},\n",
       " 'Personid': {},\n",
       " 'Placeid': {},\n",
       " 'Postid': {},\n",
       " 'Tagid': {},\n",
       " 'TagClassid': {}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Initialize `switch_namespace` \"\"\"\n",
    "\n",
    "for df in vertices.values():\n",
    "    namespace = get_namespace(df.columns[0])\n",
    "    switch_namespace[namespace] = dict()\n",
    "\n",
    "switch_namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping `origin_id` to `uni_id`: 100%|██████████| 3181724/3181724 [00:03<00:00, 1037593.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Commentid',\n",
       " 'Forumid',\n",
       " 'Organisationid',\n",
       " 'Personid',\n",
       " 'Placeid',\n",
       " 'Postid',\n",
       " 'TagClassid',\n",
       " 'Tagid'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Re-arrange all `:ID($AnyNamespace)` \"\"\"\n",
    "\n",
    "curr_global_id = 0\n",
    "\n",
    "with tqdm(desc=\"Mapping `origin_id` to `uni_id`\", total=vertex_num) as bar:\n",
    "    for df in vertices.values():\n",
    "        namespace = get_namespace(df.columns[0])\n",
    "        map = switch_namespace[namespace]\n",
    "        for row in df.rows():\n",
    "            map[int(row[0])] = curr_global_id\n",
    "            curr_global_id += 1\n",
    "            bar.update(1)\n",
    "\n",
    "assert curr_global_id == vertex_num\n",
    "set(switch_namespace.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PREFIX = \"./out\"\n",
    "ORIGINAL_QUERY_PREFIX = f\"{OUT_PREFIX}/original\"\n",
    "BI_11_DG = f\"{ORIGINAL_QUERY_PREFIX}/data_graph.txt\"\n",
    "BI_11_CHINA_QG = f\"{ORIGINAL_QUERY_PREFIX}/china_query_graph.txt\"\n",
    "BI_11_INDIA_QG = f\"{ORIGINAL_QUERY_PREFIX}/india_query_graph.txt\"\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(ORIGINAL_QUERY_PREFIX):\n",
    "    os.makedirs(ORIGINAL_QUERY_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build map of `vertex.uni_id -> label`: 100%|██████████| 3181724/3181724 [00:02<00:00, 1553599.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'China',\n",
       " 'India',\n",
       " 'city',\n",
       " 'comment',\n",
       " 'company',\n",
       " 'continent',\n",
       " 'country',\n",
       " 'forum',\n",
       " 'person',\n",
       " 'post',\n",
       " 'tag',\n",
       " 'tagclass',\n",
       " 'university'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Build map of `vertex.uni_id -> label` \"\"\"\n",
    "\n",
    "labels = dict[int, str]()\n",
    "label_set = set[str]()\n",
    "\n",
    "\n",
    "def place_op(df: DataFrame, gen_new_country_tag_for_bi_10: bool = False):\n",
    "    namespace = get_namespace(df.columns[0])\n",
    "    map = switch_namespace[namespace]\n",
    "    slice = df.select(\n",
    "        [\n",
    "            pl.col(df.columns[0]),\n",
    "            pl.col(\"name\"),\n",
    "            pl.col(\":TYPE\"),\n",
    "        ]\n",
    "    )\n",
    "    for origin_id, name, ty in slice.rows():\n",
    "        origin_id, name, label = int(origin_id), str(name), str(ty)\n",
    "        uni_id = map[origin_id]\n",
    "        if name in [\"China\", \"India\"]:\n",
    "            label = name\n",
    "        elif gen_new_country_tag_for_bi_10 and origin_id < 10:\n",
    "            label = f\"country_bi_10\"\n",
    "        labels[uni_id] = label\n",
    "        label_set.add(label)\n",
    "        bar.update(1)\n",
    "\n",
    "\n",
    "def normal_op(df: DataFrame):\n",
    "    namespace = get_namespace(df.columns[0])\n",
    "    map = switch_namespace[namespace]\n",
    "    slice = df.select(\n",
    "        [\n",
    "            pl.col(df.columns[0]),\n",
    "            pl.col(\":TYPE\" if \":TYPE\" in df.columns else \":LABEL\"),\n",
    "        ]\n",
    "    )\n",
    "    for origin_id, label in slice.rows():\n",
    "        uni_id = map[int(origin_id)]\n",
    "        labels[uni_id] = str(label)\n",
    "        label_set.add(str(label))\n",
    "        bar.update(1)\n",
    "\n",
    "\n",
    "def vertex_op(df_name: str, df: DataFrame, gen_new_country_tag_for_bi_10: bool = False):\n",
    "    place_op(df, gen_new_country_tag_for_bi_10) if df_name == \"place\" else normal_op(df)\n",
    "\n",
    "\n",
    "with tqdm(desc=\"Build map of `vertex.uni_id -> label`\", total=vertex_num) as bar:\n",
    "    for df_name, df in vertices.items():\n",
    "        vertex_op(df_name, df)\n",
    "\n",
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build edges in format: `(src_id, dst_id)`: 100%|██████████| 17256038/17256038 [00:17<00:00, 989369.78it/s] \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Build edges in format: `(src_id, dst_id)` \"\"\"\n",
    "\n",
    "edges = set[tuple[int, int]]()\n",
    "\n",
    "with tqdm(desc=\"Build edges in format: `(src_id, dst_id)`\", total=edge_num) as bar:\n",
    "    for df_name, df in raw_edges.items():\n",
    "        src_namespace = get_namespace(df.columns[0])\n",
    "        dst_namespace = get_namespace(df.columns[1])\n",
    "        src_map = switch_namespace[src_namespace]\n",
    "        dst_map = switch_namespace[dst_namespace]\n",
    "        slice = df.select(\n",
    "            [\n",
    "                pl.col(df.columns[0]),\n",
    "                pl.col(df.columns[1]),\n",
    "            ]\n",
    "        )\n",
    "        for src_id, dst_id in slice.rows():\n",
    "            src_uni_id = src_map[int(src_id)]\n",
    "            dst_uni_id = dst_map[int(dst_id)]\n",
    "            edges.add((src_uni_id, dst_uni_id))\n",
    "            bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `./out/original/data_graph.txt` already exists\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Write into `data_graph.txt` \"\"\"\n",
    "\n",
    "if not os.path.exists(BI_11_DG):\n",
    "    with open(BI_11_DG, \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(labels)}\\n\")\n",
    "        with tqdm(\n",
    "            desc=\"Writing `labels` into `data_graph.txt`\", total=len(labels)\n",
    "        ) as bar:\n",
    "            for i in range(len(labels)):\n",
    "                f.write(f\"{labels[i]}\\n\")\n",
    "                bar.update(1)\n",
    "        f.write(f\"{len(edges)}\\n\")\n",
    "        with tqdm(desc=\"Writing `edges` into `data_graph.txt\", total=len(edges)) as bar:\n",
    "            for src, dst in edges:\n",
    "                f.write(f\"{src} {dst}\\n\")\n",
    "                bar.update(1)\n",
    "else:\n",
    "    print(f\"File `{BI_11_DG}` already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Build `India` and `China` query graph \"\"\"\n",
    "\n",
    "china_query_graph_labels = [\"China\"] + [\"city\"] * 3 + [\"person\"] * 3\n",
    "china_query_graph_edges = [\n",
    "    (1, 0),\n",
    "    (2, 0),\n",
    "    (3, 0),\n",
    "    (4, 1),\n",
    "    (5, 2),\n",
    "    (6, 3),\n",
    "    (4, 5),\n",
    "    (5, 6),\n",
    "    (6, 4),\n",
    "]\n",
    "\n",
    "india_query_graph_labels = [\"India\"] + [\"city\"] * 3 + [\"person\"] * 3\n",
    "india_query_graph_edges = china_query_graph_edges\n",
    "\n",
    "if not os.path.exists(BI_11_CHINA_QG):\n",
    "    with open(BI_11_CHINA_QG, \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(china_query_graph_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in china_query_graph_labels]\n",
    "        f.write(f\"{len(china_query_graph_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in china_query_graph_edges]\n",
    "\n",
    "if not os.path.exists(BI_11_INDIA_QG):\n",
    "    with open(BI_11_INDIA_QG, \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(india_query_graph_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in india_query_graph_labels]\n",
    "        f.write(f\"{len(india_query_graph_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in india_query_graph_edges]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZED_QUERY_PREFIX = f\"{OUT_PREFIX}/optimized\"\n",
    "BI_11_DG_OPTIMIZED = f\"{OPTIMIZED_QUERY_PREFIX}/data_graph.txt\"\n",
    "BI_11_CHINA_QG_OPTIMIZED = f\"{OPTIMIZED_QUERY_PREFIX}/china_query_graph.txt\"\n",
    "BI_11_INDIA_QG_OPTIMIZED = f\"{OPTIMIZED_QUERY_PREFIX}/india_query_graph.txt\"\n",
    "\n",
    "if not os.path.exists(OPTIMIZED_QUERY_PREFIX):\n",
    "    os.makedirs(OPTIMIZED_QUERY_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load all `index edge` \"\"\"\n",
    "\n",
    "index_edges = dict[str, DataFrame]()\n",
    "\n",
    "for file in glob.glob(f\"{INDEX_EDGES_PREFIX}/*.csv\"):\n",
    "    df_name = os.path.basename(file).split(\".\")[0]\n",
    "    index_edges[df_name] = pl.read_csv(file)\n",
    "\n",
    "index_edge_num = sum(len(df) for df in index_edges.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding `index edge` into `edges`: 100%|██████████| 19593582/19593582 [00:21<00:00, 926901.33it/s] \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Add `index edge` into `edges` \"\"\"\n",
    "\n",
    "with tqdm(desc=\"Adding `index edge` into `edges`\", total=index_edge_num) as bar:\n",
    "    for df in index_edges.values():\n",
    "        src_namespace = get_namespace(df.columns[0])\n",
    "        dst_namespace = get_namespace(df.columns[1])\n",
    "        src_map = switch_namespace[src_namespace]\n",
    "        dst_map = switch_namespace[dst_namespace]\n",
    "        slice = df.select(\n",
    "            [\n",
    "                pl.col(df.columns[0]),\n",
    "                pl.col(df.columns[1]),\n",
    "            ]\n",
    "        )\n",
    "        for src_id, dst_id in slice.rows():\n",
    "            src_uni_id = src_map[int(src_id)]\n",
    "            dst_uni_id = dst_map[int(dst_id)]\n",
    "            edges.add((src_uni_id, dst_uni_id))\n",
    "            bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `./out/optimized/data_graph.txt` already exists\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Write into `data_graph.txt` \"\"\"\n",
    "\n",
    "if not os.path.exists(BI_11_DG_OPTIMIZED):\n",
    "    with open(BI_11_DG_OPTIMIZED, \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(labels)}\\n\")\n",
    "        with tqdm(\n",
    "            desc=\"Writing `labels` into `data_graph.txt`\", total=len(labels)\n",
    "        ) as bar:\n",
    "            for i in range(len(labels)):\n",
    "                f.write(f\"{labels[i]}\\n\")\n",
    "                bar.update(1)\n",
    "        f.write(f\"{len(edges)}\\n\")\n",
    "        with tqdm(desc=\"Writing `edges` into `data_graph.txt\", total=len(edges)) as bar:\n",
    "            for src, dst in edges:\n",
    "                f.write(f\"{src} {dst}\\n\")\n",
    "                bar.update(1)\n",
    "else:\n",
    "    print(f\"File `{BI_11_DG_OPTIMIZED}` already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Build `India` and `China` query graph \"\"\"\n",
    "\n",
    "china_query_graph_labels = [\"China\"] + [\"person\"] * 3\n",
    "china_query_graph_edges = [\n",
    "    (1, 0),\n",
    "    (2, 0),\n",
    "    (3, 0),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 1),\n",
    "]\n",
    "\n",
    "india_query_graph_labels = [\"India\"] + [\"person\"] * 3\n",
    "india_query_graph_edges = china_query_graph_edges\n",
    "\n",
    "if not os.path.exists(BI_11_CHINA_QG_OPTIMIZED):\n",
    "    with open(BI_11_CHINA_QG_OPTIMIZED, \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(china_query_graph_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in china_query_graph_labels]\n",
    "        f.write(f\"{len(china_query_graph_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in china_query_graph_edges]\n",
    "\n",
    "if not os.path.exists(BI_11_INDIA_QG_OPTIMIZED):\n",
    "    with open(BI_11_INDIA_QG_OPTIMIZED, \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(india_query_graph_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in india_query_graph_labels]\n",
    "        f.write(f\"{len(india_query_graph_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in india_query_graph_edges]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute `Query`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BI_11_DG = f\"{ORIGINAL_QUERY_PREFIX}/data_graph.txt\"\n",
    "BI_11_CHINA_QG = f\"{ORIGINAL_QUERY_PREFIX}/china_query_graph.txt\"\n",
    "BI_11_INDIA_QG = f\"{ORIGINAL_QUERY_PREFIX}/india_query_graph.txt\"\n",
    "BI_11_DG_OPTIMIZED = f\"{OPTIMIZED_QUERY_PREFIX}/data_graph.txt\"\n",
    "BI_11_CHINA_QG_OPTIMIZED = f\"{OPTIMIZED_QUERY_PREFIX}/china_query_graph.txt\"\n",
    "BI_11_INDIA_QG_OPTIMIZED = f\"{OPTIMIZED_QUERY_PREFIX}/india_query_graph.txt\"\n",
    "\n",
    "\n",
    "LOG_PREFIX = \"./log\"\n",
    "\n",
    "ORIGINAL_LOG_PREFIX = f\"{LOG_PREFIX}/original\"\n",
    "OPTIMIZED_LOG_PREFIX = f\"{LOG_PREFIX}/optimized\"\n",
    "BI_11_ORIGINAL_LOG_PRE = f\"{ORIGINAL_LOG_PREFIX}/BI_11\"\n",
    "BI_11_OPTIMIZED_LOG_PRE = f\"{OPTIMIZED_LOG_PREFIX}/BI_11\"\n",
    "\n",
    "\n",
    "\n",
    "BI_11_ORIGINAL_CHINA_RESULT = f\"{BI_11_ORIGINAL_LOG_PRE}/china_match_result.txt\"\n",
    "BI_11_ORIGINAL_INDIA_RESULT = f\"{BI_11_ORIGINAL_LOG_PRE}/india_match_result.txt\"\n",
    "BI_11_OPTIMIZED_CHINA_RESULT = f\"{BI_11_OPTIMIZED_LOG_PRE}/china_match_result.txt\"\n",
    "BI_11_OPTIMIZED_INDIA_RESULT = f\"{BI_11_OPTIMIZED_LOG_PRE}/india_match_result.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(BI_11_ORIGINAL_LOG_PRE):\n",
    "    os.makedirs(BI_11_ORIGINAL_LOG_PRE)\n",
    "if not os.path.exists(BI_11_OPTIMIZED_LOG_PRE):\n",
    "    os.makedirs(BI_11_OPTIMIZED_LOG_PRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Args \"\"\"\n",
    "\n",
    "\"\"\" ./VEQ_M_100k -dg <data_graph_path> -qg <query_graph_path> \"\"\"\n",
    "\n",
    "import platform\n",
    "\n",
    "wsl_if_on_windows = [\"wsl\"] if platform.system() == \"Windows\" else []\n",
    "\n",
    "original_china_match_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_11_DG,\n",
    "    \"-qg\",\n",
    "    BI_11_CHINA_QG,\n",
    "]\n",
    "original_india_match_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_11_DG,\n",
    "    \"-qg\",\n",
    "    BI_11_INDIA_QG,\n",
    "]\n",
    "\n",
    "optimized_china_match_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_11_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    BI_11_CHINA_QG_OPTIMIZED,\n",
    "]\n",
    "optimized_india_match_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_11_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    BI_11_INDIA_QG_OPTIMIZED,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `./log/original/BI_11/china_match_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 6572.88\n",
      "\n",
      "File `./log/original/BI_11/india_match_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 6399.13\n",
      "\n",
      "File `./log/optimized/BI_11/china_match_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 2892.31\n",
      "\n",
      "File `./log/optimized/BI_11/india_match_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 3315.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Exec `match` on `original` \"\"\"\n",
    "\n",
    "original_time_table = []\n",
    "\n",
    "run_veq_m_100k(\n",
    "    BI_11_ORIGINAL_CHINA_RESULT,\n",
    "    \"original_china_match\",\n",
    "    original_china_match_args,\n",
    "    original_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    BI_11_ORIGINAL_INDIA_RESULT,\n",
    "    \"original_india_match\",\n",
    "    original_india_match_args,\n",
    "    original_time_table,\n",
    ")\n",
    "\n",
    "\"\"\" Exec `match` on `optimized` \"\"\"\n",
    "\n",
    "optimized_time_table = []\n",
    "\n",
    "run_veq_m_100k(\n",
    "    BI_11_OPTIMIZED_CHINA_RESULT,\n",
    "    \"optimized_china_match\",\n",
    "    optimized_china_match_args,\n",
    "    optimized_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    BI_11_OPTIMIZED_INDIA_RESULT,\n",
    "    \"optimized_india_match\",\n",
    "    optimized_india_match_args,\n",
    "    optimized_time_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between: `original_china/india_match` & `optimized_china/india_match`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>task</th><th>original (ms)</th><th>optimized (ms)</th></tr><tr><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;china_match&quot;</td><td>6572.88</td><td>2892.31</td></tr><tr><td>&quot;india_match&quot;</td><td>6399.13</td><td>3315.39</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌─────────────┬───────────────┬────────────────┐\n",
       "│ task        ┆ original (ms) ┆ optimized (ms) │\n",
       "│ ---         ┆ ---           ┆ ---            │\n",
       "│ str         ┆ f64           ┆ f64            │\n",
       "╞═════════════╪═══════════════╪════════════════╡\n",
       "│ china_match ┆ 6572.88       ┆ 2892.31        │\n",
       "│ india_match ┆ 6399.13       ┆ 3315.39        │\n",
       "└─────────────┴───────────────┴────────────────┘"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Show BI-11 `comparison data-frame` \"\"\"\n",
    "\n",
    "print(\n",
    "    \"Comparison between: `original_china/india_match` & `optimized_china/india_match`\"\n",
    ")\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"task\": [\"china_match\", \"india_match\"],\n",
    "        \"original (ms)\": original_time_table,\n",
    "        \"optimized (ms)\": optimized_time_table,\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DG\n",
    "BI_10_DG = BI_11_DG\n",
    "BI_10_DG_OPTIMIZED = BI_11_DG_OPTIMIZED\n",
    "\n",
    "# China QG\n",
    "SHORT_CHINA_POST_QG = \"short_china_post_query_graph.txt\"\n",
    "SHORT_CHINA_COMMENT_QG = \"short_china_comment_query_graph.txt\"\n",
    "LONG_CHINA_POST_QG = \"long_china_post_query_graph.txt\"\n",
    "LONG_CHINA_COMMENT_QG = \"long_china_comment_query_graph.txt\"\n",
    "\n",
    "# India QG\n",
    "SHORT_INDIA_POST_QG = \"short_india_post_query_graph.txt\"\n",
    "SHORT_INDIA_COMMENT_QG = \"short_india_comment_query_graph.txt\"\n",
    "LONG_INDIA_POST_QG = \"long_india_post_query_graph.txt\"\n",
    "LONG_INDIA_COMMENT_QG = \"long_india_comment_query_graph.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# China Log(Result)\n",
    "SHORT_CHINA_POST_RES = \"short_china_post_result.txt\"\n",
    "SHORT_CHINA_COMMENT_RES = \"short_china_comment_result.txt\"\n",
    "LONG_CHINA_POST_RES = \"long_china_post_result.txt\"\n",
    "LONG_CHINA_COMMENT_RES = \"long_china_comment_result.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# India Log(Result)\n",
    "SHORT_INDIA_POST_RES = \"short_india_post_result.txt\"\n",
    "SHORT_INDIA_COMMENT_RES = \"short_india_comment_result.txt\"\n",
    "LONG_INDIA_POST_RES = \"long_india_post_result.txt\"\n",
    "LONG_INDIA_COMMENT_RES = \"long_india_comment_result.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirname\n",
    "BI_10_DIRNAME = \"BI_10\"\n",
    "BI_10_ORIGINAL_Q_PRE = ORIGINAL_QUERY_PREFIX\n",
    "BI_10_OPTIMIZED_Q_PRE = OPTIMIZED_QUERY_PREFIX\n",
    "BI_10_ORIGINAL_L_PRE = f\"{ORIGINAL_LOG_PREFIX}/{BI_10_DIRNAME}\"\n",
    "BI_10_OPTIMIZED_L_PRE = f\"{OPTIMIZED_LOG_PREFIX}/{BI_10_DIRNAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(BI_10_ORIGINAL_L_PRE):\n",
    "    os.makedirs(BI_10_ORIGINAL_L_PRE)\n",
    "if not os.path.exists(BI_10_OPTIMIZED_L_PRE):\n",
    "    os.makedirs(BI_10_OPTIMIZED_L_PRE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" labels & edges \"\"\"\n",
    "\n",
    "original_short_edges = [(0, 1), (1, 6), (6, 2), (2, 3), (2, 4), (4, 5)] + [\n",
    "    (6, 7),\n",
    "    (7, 8),\n",
    "    (8, 9),\n",
    "]\n",
    "original_long_edges = original_short_edges + [(9, 10)]\n",
    "\n",
    "original_short_china_post_labels = [\n",
    "    \"China\",\n",
    "    \"city\",\n",
    "    \"post\",\n",
    "    \"tag\",\n",
    "    \"tag\",\n",
    "    \"tagclass\",\n",
    "] + [\"person\"] * 4\n",
    "original_long_china_post_labels = original_short_china_post_labels + [\"person\"]\n",
    "original_short_china_comment_labels = [\n",
    "    \"China\",\n",
    "    \"city\",\n",
    "    \"comment\",\n",
    "    \"tag\",\n",
    "    \"tag\",\n",
    "    \"tagclass\",\n",
    "] + [\"person\"] * 4\n",
    "original_long_china_comment_labels = original_short_china_comment_labels + [\"person\"]\n",
    "original_short_india_post_labels = [\n",
    "    \"India\",\n",
    "    \"city\",\n",
    "    \"post\",\n",
    "    \"tag\",\n",
    "    \"tag\",\n",
    "    \"tagclass\",\n",
    "] + [\"person\"] * 4\n",
    "original_long_india_post_labels = original_short_india_post_labels + [\"person\"]\n",
    "original_short_india_comment_labels = [\n",
    "    \"India\",\n",
    "    \"city\",\n",
    "    \"comment\",\n",
    "    \"tag\",\n",
    "    \"tag\",\n",
    "    \"tagclass\",\n",
    "] + [\"person\"] * 4\n",
    "original_long_india_comment_labels = original_short_india_comment_labels + [\"person\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Init Original Query Graph \"\"\"\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_CHINA_POST_QG}\"):\n",
    "    with open(f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_CHINA_POST_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(original_short_china_post_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in original_short_china_post_labels]\n",
    "        f.write(f\"{len(original_short_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in original_short_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_CHINA_POST_QG}\"):\n",
    "    with open(f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_CHINA_POST_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(original_long_china_post_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in original_long_china_post_labels]\n",
    "        f.write(f\"{len(original_long_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in original_long_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_CHINA_COMMENT_QG}\"):\n",
    "    with open(f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_CHINA_COMMENT_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(original_short_china_comment_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in original_short_china_comment_labels]\n",
    "        f.write(f\"{len(original_short_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in original_short_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_CHINA_COMMENT_QG}\"):\n",
    "    with open(f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_CHINA_COMMENT_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(original_long_china_comment_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in original_long_china_comment_labels]\n",
    "        f.write(f\"{len(original_long_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in original_long_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_INDIA_POST_QG}\"):\n",
    "    with open(f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_INDIA_POST_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(original_short_india_post_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in original_short_india_post_labels]\n",
    "        f.write(f\"{len(original_short_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in original_short_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_INDIA_POST_QG}\"):\n",
    "    with open(f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_INDIA_POST_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(original_long_india_post_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in original_long_india_post_labels]\n",
    "        f.write(f\"{len(original_long_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in original_long_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_INDIA_COMMENT_QG}\"):\n",
    "    with open(f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_INDIA_COMMENT_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(original_short_india_comment_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in original_short_india_comment_labels]\n",
    "        f.write(f\"{len(original_short_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in original_short_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_INDIA_COMMENT_QG}\"):\n",
    "    with open(f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_INDIA_COMMENT_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(original_long_india_comment_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in original_long_india_comment_labels]\n",
    "        f.write(f\"{len(original_long_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in original_long_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" args \"\"\"\n",
    "\n",
    "original_short_china_post_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_CHINA_POST_QG}\",\n",
    "]\n",
    "original_long_china_post_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_CHINA_POST_QG}\",\n",
    "]\n",
    "original_short_china_comment_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_CHINA_COMMENT_QG}\",\n",
    "]\n",
    "original_long_china_comment_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_CHINA_COMMENT_QG}\",\n",
    "]\n",
    "original_short_india_post_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_INDIA_POST_QG}\",\n",
    "]\n",
    "original_long_india_post_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_INDIA_POST_QG}\",\n",
    "]\n",
    "original_short_india_comment_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_ORIGINAL_Q_PRE}/{SHORT_INDIA_COMMENT_QG}\",\n",
    "]\n",
    "original_long_india_comment_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_ORIGINAL_Q_PRE}/{LONG_INDIA_COMMENT_QG}\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `./log/original/BI_10/short_china_post_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 768.04\n",
      "\n",
      "File `./log/original/BI_10/long_china_post_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 330.352\n",
      "\n",
      "File `./log/original/BI_10/short_china_comment_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 1486.43\n",
      "\n",
      "File `./log/original/BI_10/long_china_comment_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 887.005\n",
      "\n",
      "File `./log/original/BI_10/short_india_post_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 401.596\n",
      "\n",
      "File `./log/original/BI_10/long_india_post_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 395.917\n",
      "\n",
      "File `./log/original/BI_10/short_india_comment_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 1254.6\n",
      "\n",
      "File `./log/original/BI_10/long_india_comment_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 977.802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" exec \"\"\"\n",
    "\n",
    "new_original_time_table = []\n",
    "\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_ORIGINAL_L_PRE}/{SHORT_CHINA_POST_RES}\",\n",
    "    \"original_short_china_post\",\n",
    "    original_short_china_post_args,\n",
    "    new_original_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_ORIGINAL_L_PRE}/{LONG_CHINA_POST_RES}\",\n",
    "    \"original_long_china_post\",\n",
    "    original_long_china_post_args,\n",
    "    new_original_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_ORIGINAL_L_PRE}/{SHORT_CHINA_COMMENT_RES}\",\n",
    "    \"original_short_china_comment\",\n",
    "    original_short_china_comment_args,\n",
    "    new_original_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_ORIGINAL_L_PRE}/{LONG_CHINA_COMMENT_RES}\",\n",
    "    \"original_long_china_comment\",\n",
    "    original_long_china_comment_args,\n",
    "    new_original_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_ORIGINAL_L_PRE}/{SHORT_INDIA_POST_RES}\",\n",
    "    \"original_short_india_post\",\n",
    "    original_short_india_post_args,\n",
    "    new_original_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_ORIGINAL_L_PRE}/{LONG_INDIA_POST_RES}\",\n",
    "    \"original_long_india_post\",\n",
    "    original_long_india_post_args,\n",
    "    new_original_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_ORIGINAL_L_PRE}/{SHORT_INDIA_COMMENT_RES}\",\n",
    "    \"original_short_india_comment\",\n",
    "    original_short_india_comment_args,\n",
    "    new_original_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_ORIGINAL_L_PRE}/{LONG_INDIA_COMMENT_RES}\",\n",
    "    \"original_long_india_comment\",\n",
    "    original_long_india_comment_args,\n",
    "    new_original_time_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" labels & edges \"\"\"\n",
    "\n",
    "optimized_short_edges = [(0, 5), (5, 1), (1, 2), (1, 3), (3, 4)] + [\n",
    "    (5, 6),\n",
    "    (6, 7),\n",
    "    (7, 8),\n",
    "]\n",
    "optimized_long_edges = optimized_short_edges + [(8, 9)]\n",
    "\n",
    "optimized_short_china_post_labels = [\n",
    "    \"China\",\n",
    "    \"post\",\n",
    "    \"tag\",\n",
    "    \"tag\",\n",
    "    \"tagclass\",\n",
    "] + [\"person\"] * 4\n",
    "optimized_long_china_post_labels = optimized_short_china_post_labels + [\"person\"]\n",
    "optimized_short_china_comment_labels = [\n",
    "    \"China\",\n",
    "    \"comment\",\n",
    "    \"tag\",\n",
    "    \"tag\",\n",
    "    \"tagclass\",\n",
    "] + [\"person\"] * 4\n",
    "optimized_long_china_comment_labels = optimized_short_china_comment_labels + [\"person\"]\n",
    "optimized_short_india_post_labels = [\n",
    "    \"India\",\n",
    "    \"post\",\n",
    "    \"tag\",\n",
    "    \"tag\",\n",
    "    \"tagclass\",\n",
    "] + [\"person\"] * 4\n",
    "optimized_long_india_post_labels = optimized_short_india_post_labels + [\"person\"]\n",
    "optimized_short_india_comment_labels = [\n",
    "    \"India\",\n",
    "    \"comment\",\n",
    "    \"tag\",\n",
    "    \"tag\",\n",
    "    \"tagclass\",\n",
    "] + [\"person\"] * 4\n",
    "optimized_long_india_comment_labels = optimized_short_india_comment_labels + [\"person\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Init Optimized Query Graph \"\"\"\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_CHINA_POST_QG}\"):\n",
    "    with open(f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_CHINA_POST_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(optimized_short_china_post_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in optimized_short_china_post_labels]\n",
    "        f.write(f\"{len(optimized_short_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in optimized_short_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_CHINA_POST_QG}\"):\n",
    "    with open(f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_CHINA_POST_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(optimized_long_china_post_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in optimized_long_china_post_labels]\n",
    "        f.write(f\"{len(optimized_long_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in optimized_long_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_CHINA_COMMENT_QG}\"):\n",
    "    with open(f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_CHINA_COMMENT_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(optimized_short_china_comment_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in optimized_short_china_comment_labels]\n",
    "        f.write(f\"{len(optimized_short_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in optimized_short_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_CHINA_COMMENT_QG}\"):\n",
    "    with open(f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_CHINA_COMMENT_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(optimized_long_china_comment_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in optimized_long_china_comment_labels]\n",
    "        f.write(f\"{len(optimized_long_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in optimized_long_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_INDIA_POST_QG}\"):\n",
    "    with open(f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_INDIA_POST_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(optimized_short_india_post_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in optimized_short_india_post_labels]\n",
    "        f.write(f\"{len(optimized_short_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in optimized_short_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_INDIA_POST_QG}\"):\n",
    "    with open(f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_INDIA_POST_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(optimized_long_india_post_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in optimized_long_india_post_labels]\n",
    "        f.write(f\"{len(optimized_long_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in optimized_long_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_INDIA_COMMENT_QG}\"):\n",
    "    with open(f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_INDIA_COMMENT_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(optimized_short_india_comment_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in optimized_short_india_comment_labels]\n",
    "        f.write(f\"{len(optimized_short_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in optimized_short_edges]\n",
    "\n",
    "if not os.path.exists(f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_INDIA_COMMENT_QG}\"):\n",
    "    with open(f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_INDIA_COMMENT_QG}\", \"w\") as f:\n",
    "        f.write(\"#0\\n\")\n",
    "        f.write(f\"{len(optimized_long_india_comment_labels)}\\n\")\n",
    "        [f.write(f\"{label}\\n\") for label in optimized_long_india_comment_labels]\n",
    "        f.write(f\"{len(optimized_long_edges)}\\n\")\n",
    "        [f.write(f\"{src} {dst}\\n\") for src, dst in optimized_long_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" args \"\"\"\n",
    "\n",
    "optimized_short_china_post_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_CHINA_POST_QG}\",\n",
    "]\n",
    "optimized_long_china_post_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_CHINA_POST_QG}\",\n",
    "]\n",
    "optimized_short_china_comment_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_CHINA_COMMENT_QG}\",\n",
    "]\n",
    "optimized_long_china_comment_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_CHINA_COMMENT_QG}\",\n",
    "]\n",
    "optimized_short_india_post_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_INDIA_POST_QG}\",\n",
    "]\n",
    "optimized_long_india_post_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_INDIA_POST_QG}\",\n",
    "]\n",
    "optimized_short_india_comment_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_OPTIMIZED_Q_PRE}/{SHORT_INDIA_COMMENT_QG}\",\n",
    "]\n",
    "optimized_long_india_comment_args = wsl_if_on_windows + [\n",
    "    \"./VEQ_M_100k\",\n",
    "    \"-dg\",\n",
    "    BI_10_DG_OPTIMIZED,\n",
    "    \"-qg\",\n",
    "    f\"{BI_10_OPTIMIZED_Q_PRE}/{LONG_INDIA_COMMENT_QG}\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `./log/optimized/BI_10/short_china_post_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 707.368\n",
      "\n",
      "File `./log/optimized/BI_10/long_china_post_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 395.018\n",
      "\n",
      "File `./log/optimized/BI_10/short_china_comment_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 1996.5\n",
      "\n",
      "File `./log/optimized/BI_10/long_china_comment_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 1235.61\n",
      "\n",
      "File `./log/optimized/BI_10/short_india_post_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 683.904\n",
      "\n",
      "File `./log/optimized/BI_10/long_india_post_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 346.558\n",
      "\n",
      "File `./log/optimized/BI_10/short_india_comment_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 1469.59\n",
      "\n",
      "File `./log/optimized/BI_10/long_india_comment_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 1287.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" exec \"\"\"\n",
    "\n",
    "new_optimized_time_table = []\n",
    "\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_OPTIMIZED_L_PRE}/{SHORT_CHINA_POST_RES}\",\n",
    "    \"optimized_short_china_post\",\n",
    "    optimized_short_china_post_args,\n",
    "    new_optimized_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_OPTIMIZED_L_PRE}/{LONG_CHINA_POST_RES}\",\n",
    "    \"optimized_long_china_post\",\n",
    "    optimized_long_china_post_args,\n",
    "    new_optimized_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_OPTIMIZED_L_PRE}/{SHORT_CHINA_COMMENT_RES}\",\n",
    "    \"optimized_short_china_comment\",\n",
    "    optimized_short_china_comment_args,\n",
    "    new_optimized_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_OPTIMIZED_L_PRE}/{LONG_CHINA_COMMENT_RES}\",\n",
    "    \"optimized_long_china_comment\",\n",
    "    optimized_long_china_comment_args,\n",
    "    new_optimized_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_OPTIMIZED_L_PRE}/{SHORT_INDIA_POST_RES}\",\n",
    "    \"optimized_short_india_post\",\n",
    "    optimized_short_india_post_args,\n",
    "    new_optimized_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_OPTIMIZED_L_PRE}/{LONG_INDIA_POST_RES}\",\n",
    "    \"optimized_long_india_post\",\n",
    "    optimized_long_india_post_args,\n",
    "    new_optimized_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_OPTIMIZED_L_PRE}/{SHORT_INDIA_COMMENT_RES}\",\n",
    "    \"optimized_short_india_comment\",\n",
    "    optimized_short_india_comment_args,\n",
    "    new_optimized_time_table,\n",
    ")\n",
    "run_veq_m_100k(\n",
    "    f\"{BI_10_OPTIMIZED_L_PRE}/{LONG_INDIA_COMMENT_RES}\",\n",
    "    \"optimized_long_india_comment\",\n",
    "    optimized_long_india_comment_args,\n",
    "    new_optimized_time_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between: `original_china/india_match` & `optimized_china/india_match`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>task</th><th>original (ms)</th><th>optimized (ms)</th></tr><tr><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;short_china_po…</td><td>768.04</td><td>707.368</td></tr><tr><td>&quot;long_china_pos…</td><td>330.352</td><td>395.018</td></tr><tr><td>&quot;short_china_co…</td><td>1486.43</td><td>1996.5</td></tr><tr><td>&quot;long_china_com…</td><td>887.005</td><td>1235.61</td></tr><tr><td>&quot;short_india_po…</td><td>401.596</td><td>683.904</td></tr><tr><td>&quot;long_india_pos…</td><td>395.917</td><td>346.558</td></tr><tr><td>&quot;short_india_co…</td><td>1254.6</td><td>1469.59</td></tr><tr><td>&quot;long_india_com…</td><td>977.802</td><td>1287.6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 3)\n",
       "┌─────────────────────┬───────────────┬────────────────┐\n",
       "│ task                ┆ original (ms) ┆ optimized (ms) │\n",
       "│ ---                 ┆ ---           ┆ ---            │\n",
       "│ str                 ┆ f64           ┆ f64            │\n",
       "╞═════════════════════╪═══════════════╪════════════════╡\n",
       "│ short_china_post    ┆ 768.04        ┆ 707.368        │\n",
       "│ long_china_post     ┆ 330.352       ┆ 395.018        │\n",
       "│ short_china_comment ┆ 1486.43       ┆ 1996.5         │\n",
       "│ long_china_comment  ┆ 887.005       ┆ 1235.61        │\n",
       "│ short_india_post    ┆ 401.596       ┆ 683.904        │\n",
       "│ long_india_post     ┆ 395.917       ┆ 346.558        │\n",
       "│ short_india_comment ┆ 1254.6        ┆ 1469.59        │\n",
       "│ long_india_comment  ┆ 977.802       ┆ 1287.6         │\n",
       "└─────────────────────┴───────────────┴────────────────┘"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Show BI-10 `comparison data-frame` \"\"\"\n",
    "\n",
    "print(\n",
    "    \"Comparison between: `original_china/india_match` & `optimized_china/india_match`\"\n",
    ")\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"task\": [\n",
    "            \"short_china_post\",\n",
    "            \"long_china_post\",\n",
    "            \"short_china_comment\",\n",
    "            \"long_china_comment\",\n",
    "            \"short_india_post\",\n",
    "            \"long_india_post\",\n",
    "            \"short_india_comment\",\n",
    "            \"long_india_comment\",\n",
    "        ],\n",
    "        \"original (ms)\": new_original_time_table,\n",
    "        \"optimized (ms)\": new_optimized_time_table,\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OriginalBI3:\n",
    "    dirname = \"BI_3\"\n",
    "    labels = [\"China\", \"city\", \"person\", \"forum\", \"post\", \"comment\", \"tag\", \"tagclass\"]\n",
    "    edges = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7)]\n",
    "    task_name = \"original_china_bi3\"\n",
    "    query_graph_name = \"original_china_bi3_query_graph.txt\"\n",
    "    log_name = \"original_china_bi3_result.txt\"\n",
    "    time_table = list[float]()\n",
    "    args = wsl_if_on_windows + [\n",
    "        \"./VEQ_M_100k\",\n",
    "        \"-dg\",\n",
    "        BI_11_DG,\n",
    "        \"-qg\",\n",
    "        f\"{ORIGINAL_QUERY_PREFIX}/{query_graph_name}\",\n",
    "    ]\n",
    "\n",
    "    def build_query_graph(self):\n",
    "        query_prefix = ORIGINAL_QUERY_PREFIX\n",
    "        if not os.path.exists(f\"{query_prefix}/{self.query_graph_name}\"):\n",
    "            with open(f\"{query_prefix}/{self.query_graph_name}\", \"w\") as f:\n",
    "                f.write(\"#0\\n\")\n",
    "                f.write(f\"{len(self.labels)}\\n\")\n",
    "                [f.write(f\"{label}\\n\") for label in self.labels]\n",
    "                f.write(f\"{len(self.edges)}\\n\")\n",
    "                [f.write(f\"{src} {dst}\\n\") for src, dst in self.edges]\n",
    "\n",
    "    def run_query(self):\n",
    "        log_prefix = f\"{ORIGINAL_LOG_PREFIX}/{self.dirname}\"\n",
    "        if not os.path.exists(log_prefix):\n",
    "            os.makedirs(log_prefix)\n",
    "        run_veq_m_100k(\n",
    "            f\"{log_prefix}/{self.log_name}\",\n",
    "            self.task_name,\n",
    "            self.args,\n",
    "            self.time_table,\n",
    "        )\n",
    "\n",
    "\n",
    "original_query_proc = OriginalBI3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Build `query graph` \"\"\"\n",
    "\n",
    "original_query_proc.build_query_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `./log/original/BI_3/original_china_bi3_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 24926.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Run query \"\"\"\n",
    "\n",
    "original_query_proc.run_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OptimizedBI3:\n",
    "    dirname = \"BI_3\"\n",
    "    labels = [\"China\", \"forum\", \"post\", \"comment\", \"tag\", \"tagclass\"]\n",
    "    edges = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n",
    "    task_name = \"optimized_china_bi3\"\n",
    "    query_graph_name = \"optimized_china_bi3_query_graph.txt\"\n",
    "    log_name = \"optimized_china_bi3_result.txt\"\n",
    "    time_table = list[float]()\n",
    "    args = wsl_if_on_windows + [\n",
    "        \"./VEQ_M_100k\",\n",
    "        \"-dg\",\n",
    "        BI_11_DG_OPTIMIZED,\n",
    "        \"-qg\",\n",
    "        f\"{OPTIMIZED_QUERY_PREFIX}/{query_graph_name}\",\n",
    "    ]\n",
    "\n",
    "    def build_query_graph(self):\n",
    "        query_prefix = OPTIMIZED_QUERY_PREFIX\n",
    "        if not os.path.exists(f\"{query_prefix}/{self.query_graph_name}\"):\n",
    "            with open(f\"{query_prefix}/{self.query_graph_name}\", \"w\") as f:\n",
    "                f.write(\"#0\\n\")\n",
    "                f.write(f\"{len(self.labels)}\\n\")\n",
    "                [f.write(f\"{label}\\n\") for label in self.labels]\n",
    "                f.write(f\"{len(self.edges)}\\n\")\n",
    "                [f.write(f\"{src} {dst}\\n\") for src, dst in self.edges]\n",
    "\n",
    "    def run_query(self):\n",
    "        log_prefix = f\"{OPTIMIZED_LOG_PREFIX}/{self.dirname}\"\n",
    "        if not os.path.exists(log_prefix):\n",
    "            os.makedirs(log_prefix)\n",
    "        run_veq_m_100k(\n",
    "            f\"{log_prefix}/{self.log_name}\",\n",
    "            self.task_name,\n",
    "            self.args,\n",
    "            self.time_table,\n",
    "        )\n",
    "\n",
    "\n",
    "optimized_query_proc = OptimizedBI3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Build `query graph` \"\"\"\n",
    "\n",
    "optimized_query_proc.build_query_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `./log/optimized/BI_3/optimized_china_bi3_result.txt` already exists\n",
      "    last_line ~> Processing Time (ms): 24998.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Run query \"\"\"\n",
    "\n",
    "optimized_query_proc.run_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>task</th><th>original (ms)</th><th>optimized (ms)</th></tr><tr><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;china_bi3&quot;</td><td>24926.9</td><td>24998.3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌───────────┬───────────────┬────────────────┐\n",
       "│ task      ┆ original (ms) ┆ optimized (ms) │\n",
       "│ ---       ┆ ---           ┆ ---            │\n",
       "│ str       ┆ f64           ┆ f64            │\n",
       "╞═══════════╪═══════════════╪════════════════╡\n",
       "│ china_bi3 ┆ 24926.9       ┆ 24998.3        │\n",
       "└───────────┴───────────────┴────────────────┘"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Show BI-3 `comparison data-frame` \"\"\"\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"task\": [\"china_bi3\"],\n",
    "        \"original (ms)\": original_query_proc.time_table,\n",
    "        \"optimized (ms)\": optimized_query_proc.time_table,\n",
    "    }\n",
    ")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
